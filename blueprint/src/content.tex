% In this file you should put the actual content of the blueprint.
% It will be used both by the web and the print version.
% It should *not* include the \begin{document}
%
% If you want to split the blueprint content into several files then
% the current file can be a simple sequence of \input. Otherwise It
% can start with a \section or \chapter for instance.

\chapter{Introduction}

This project is not yet complete, but intends to formalize a strengthening of the following theorem. Let $\mathbb{I} = \left[0,1\right]$ and let $n \geq 2$ be an given integer. We use $C^d$ to indicate the space of functions defined on a domain whose $d$-th derivative is continuous and use $\circ$ to indicate function composition.

\begin{theorem*}[Kolmogorov 1957]
  \label{thm:KST}
  For every $f \in C\left(\mathbb{I}^n\right) \mapsto \mathbb{R}$, there exist increasing $\psi_{p,q} \in C\left(\mathbb{I}\right) \mapsto \mathbb{R}$ that do not depend on $f$ and generally non-monotone $\chi_q \in C\left(\mathbb{R}\right) \mapsto \mathbb{R}$ that depend on $f$ and $\psi_{p,q}$, such that $f\left(x_0, x_1, \cdots, x_{n - 1}\right) = \sum\limits_{q = 0}^{2n} \chi_q \circ \Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right)$, where $\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right) \equiv \sum\limits_{p = 0}^{n - 1} \psi_{p,q}\left(x_p\right)$.
\end{theorem*}

\noindent This theorem is called the Kolmogorov Superposition Representation (KSR) or the Kolmogorov Superposition Theorem (KST) because Kolmogorov proved that a given multivariable ``target'' function, $f$, could be represented as a finite sum of compositions of univariate functions. 

The relevance of the KRT continues to be debated in the neural networks literature. On one side, many want to utilize the KSR to approximate unknown or expensive target functions. However, the ``inner'' functions, $\psi_{p,q}$, and ``outer'' functions, $\chi_q$, are not elementary, in the sense that they cannot be computed with a finite number of calls to basic functions. Thus, the KSR requires harmonic analysis and other side is skeptical that the it will ever be of much practical use.

Although the KST is perhaps surprising in its generality and simplicity, it has been proven in several ways, raising the question of what value is added by an additional proof? The extant proofs of the KST are of three kinds (and none have been formalized):

\begin{itemize}
    \item \textbf{Nonconstructive}: The most elegant proofs utilize the Baire Category Theorem to prove the \textit{existence} of inner and outer functions that satisfy the KST but do not suggest how to construct them.
    \item \textbf{Constructive}: Other proofs are considered to be constructive but do not even suggest a feasible algorithm to implement them in floating-point arithmetic.
    \item \textbf{Constructed}: Two constructions have been implemented in software but both utilize bad inner functions and worse outer functions, making them unworkable in floating-point arithmetic.
\end{itemize}

By ``bad" inner functions, we specifically mean they are in the Devil's Staircase family, that is, their derivative is zero almost everywhere on $\mathbb{I}$ but does not exist on a dense set of points. By ``worse" outer functions, we specifically mean that they are nowhere differentiable. Thus, even if $f$ were differentiable at some point, the chain rule does not apply to a compositions involving nowhere differentiable functions, so it cannot be used to compute a gradient under the original KSR. Most algorithms in statistics and supervised learning rely on gradients as part of some larger algorithm, so the KSR has not been useful for those purposes. 

Our goal is to construct decent inner functions and adequate outer functions that satisfy the KST and allow the chain rule to compute the gradient of $f$, which can then be implemented to floating-point arithmetic. Vitushkin and Khenkin proved that the inner functions in the KST cannot all be continuously differentiable. Thus, by ``decent'' inner functions, we specifically mean Lipschitz continuous functions, which satisfy $\left|\psi_{p,q}\left(x\right) - \psi_{p,q}\left(x^\prime\right)\right| \leq K\left|x - x^\prime\right|$ for some positive but finite constant $K$. The KST literature often refers to a more general definition of Lipschitz continuity (which is also termed H\"{o}lder continuity) where $\left|\psi_{p,q}\left(x\right) -   \psi_{p,q}\left(x^\prime\right)\right| \leq K\left|x - x^\prime\right|^\alpha$. Fridman and Kahane proved that the inner functions can all be weak contractions, that is, $\alpha = 1$ and $K = 1$.

Sprecher proved that there are outer functions that satisfy the KST for any target function when $\psi_{p,q}\left(x_p\right) \equiv \lambda^p \varphi\left(x_p - \frac{q}{2n}\right)$, where $\lambda > 0$ is an irrational number and $\varphi$ is a weak contraction that we call the ``core'' function. However, the only known attempt to implement the Fridman-Sprecher approach in software was made by Actor, which was unsuccessful.

Actor did succeed in reparameterizing the H\"{o}lder continuous core function proposed by Sprecher, corrected by K\"{o}ppen, and proven correct by Braun and Griebel. Actor's function is parameterized via its arc length and is Lipschitz continuous by construction. While there is graphical evidence that strongly suggests Actor's function is compatible with the KST, some aspects of the approach are not fully proved, and it requires an expensive numerical inversion of Braun and Griebel's function just to achieve a few decimal places of accuracy.

Montanelli and Yang notes the importance of constructing a Lipschitz continuous KST
\begin{quote}
We have proven upper bounds for the approximation of multivariate functions $f : [0, 1]^n \mapsto \mathbb{R}$ by deep ReLU networks, for which the curse of dimensionality is lessened. The depth and the size of the networks to approximate such functions $f$ grow like $\mathcal{O}\left(\varepsilon^{-\log n}\right)$, as opposed to $\mathcal{O}\left(\varepsilon^{-n}\right)$. The proof is based on the ability of very deep ReLU networks to implement the Kolmogorov-Arnold superposition theorem.

There are many ways in which this work could be fruitfully continued. If we were able to construct a Lipschitz continuous inner function, we would be able to
obtain $\mathcal{O}\left(\varepsilon^{-1}\right)$ estimates. Actor and Knepley designed in 2017 an algorithm to compute a Lipschitz continuous inner function, but they did not provide a method to compute the outer functions.
\end{quote}
\noindent This quote reflects the fact that the outer functions depend on the inner functions, in addition to $f$. The smoother are the inner functions, the easier it is to obtain ``adequate'' outer functions that approximate a target function to a given degree of accuracy. In short, a Lipschitz continuous KST would overcome (to first order) the curse of dimensionality when approximating $y$ on $\mathbb{I}^n$. 

Also, target functions in statistics, such as log-likelihood functions, typically depend on $N$ data points and the cost of evaluating them directly is polynomial (at best) in $N$. Once the outer functions have been calibrated to the target function, the KSR of the target function can be evaluated in parallel in essentially constant wall time regardless of $n$ or $N$. These savings could be enormous in computationally intensive applications, such as Markov Chain Monte Carlo or Large Language Models.

There are several open questions that are not even investigated in the KST literature:
\begin{enumerate}
    \item Can some proper subset of the inner functions be continuously differentiable (or smoother)? We show that if $0 < q < 2n$, then $\psi_{p,q}$ can be twice continuously differentiable.
    \item Does the core function depend on $n$, apart from being evaluated at $x - \frac{q}{2n}$? We show that $\varphi$ can be universal, although $\lambda$ does depend on $n$ in a simple fashion.    
    \item Can the set of points where $\varphi$ is not differentiable be finite? We show that $\varphi$ is not differentiable at $1$ and $-1$ but is differentiable on $\left(-1,1\right)$.
    \item Can $\varphi$ be approximated to floating-point precision? We show that $\varphi$ can be quickly approximated to any degree of accuracy. 
\end{enumerate}

Our approach is unique in that we first construct a function with the requisite properties and then show that it is a viable core function in the KSR. Chapter \ref{ch:CoreFunction} uses basic real analysis --- most of which is already formalized in the Mathlib library used by the Lean software --- to show that our candidate for $\psi$ is increasing, Lipschitz continuous, and not continuously differentiable. In addition, since $\varphi$ can be represented as a series, it is essential to demonstrate that the series converges uniformly, which is an improvement over the other constructions in the KST literature whose functions only converge pointwise. As a result, $\varphi$ can be evaluated to double precision in fewer than a hundred floating point operations, and its derivative can be evaluated at double that cost (albeit to less accuracy).

Chapter \ref{ch:Injectivity} establishes in Lean that $\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right) \equiv \sum\limits_{p = 1}^n \lambda^{p -1} \varphi\left(x_p - \frac{q}{2n}\right)$ is injective for each $q$ when $\lambda$ is a transcendental number. The proof is only slightly different from the one Sprecher has relied upon for decades that essentially extended the rational number field with an irrational $\lambda$. Much of this can leverage the theorems on cyclotomic fields that are already in Mathlib.

Chapter \ref{ch:OuterFunctions} is the least complete but is devoted to the outer functions in the KSR. Kahane utilized the notion of a Helson set, which is a subset with the characterizing property that every continuous function over this subset can be represented as a convergent Fourier series. Kahane proved necessary and sufficient conditions for a subset of $\mathbb{I}^{2n + 1}$ to be a Helson set.

\chapter{Core Function}\label{ch:CoreFunction}

\section{Main Definitions}\label{sec:MainDefinitions}

The atomic element of our KSR is the first-kind Chebyshev polynomial. Let $j$ be a generic integer that is usually non-negative, but is used in various ways in different contexts in this report.
\begin{definition}[Chebyshev polynomial of the first kind]
  \label{def:T}
  \leanok
  Let $r$ be a real number. The first-kind Chebyshev polynomial in $r$ with index $j$ is defined via a three-term recursion as
  \begin{align*}
T_j\left(r\right) \equiv 
\begin{cases}
1 & \text{if } j = 0 \\
r & \text{if } j = 1 \\
2 r T_{j - 1}\left(r\right) - T_{j - 2}\left(r\right) & \text{if } j > 1.
\end{cases}
  \end{align*}
\end{definition}
\begin{remark*}
The Mathlib library used by Lean (version 4) actually defines $T_j$ as a function of $j$ (which can be negative) that returns a polynomial (with coefficients in any commutative ring). Such generality is unnecessary here, but Mathlib also provides a metatheorem that can be used to tersely prove many properties of Chebyshev polynomials via double induction on $j$. Our notation, $T_j\left(r\right)$, corresponds to simply evaluating such a polynomial at a symbolic real number. 
\end{remark*}
We specialize $j = 2^m$ to define partial sums that approach our candidate for a core function.
\begin{definition}[$k$-th order approximator]
  \label{def:approx}
  \uses{def:T}
  \lean{ψₖ}
  \leanok
  $\varphi_k\left(r\right) \equiv \threesevenths + \offset + \halfsum{0}{k}{r}$, where $k \in \mathbb{N}$.
\end{definition}
\begin{definition}[Core function]
  \label{def:core}
  \uses{def:T}
  \lean{ψ}
  \leanok
  $\varphi\left(r\right) \equiv \threesevenths + \halfsum{0}{\infty}{r}$.
\end{definition}
\noindent For an overview of expanding a function in terms of Chebyshev polynomials, see Trefethen.

\begin{definition}[Normalizer]
  \label{def:Lambda}
  $\Lambda \equiv \sum\limits_{p = 0}^{n - 1} \lambda^p$, where $\lambda > 0$ and $n \geq 2$.
\end{definition}
\begin{definition}[Scale factor]
  \label{def:lambda_p}
  \uses{def:Lambda}
  $\lambda_p \equiv \frac{\lambda^p}{\Lambda} \in \left(0,1\right)$.
\end{definition}
\begin{definition}[Inner function]
  \label{def:inner_function}
  $\psi_{p,q}\left(x\right) \equiv \lambda_p \varphi\left(x - \frac{q}{2n}\right)$, where $x \in \mathbb{I}$ and $q \in \{0, 1, \cdots, 2n\}$.
\end{definition}

\section{Repeatedly Used Lemmas}\label{sec:RepeatedlyUsedLemmas}

\renewcommand{\thetheorem}{\Alph{theorem}}

Our Chebyshev polynomials also follow a \emph{two-term} recursion that drives nearly all other lemmas.
\begin{lemma}[Two-term recursion]
  \label{lem:TT_recursion}
  \uses{def:T}
  \lean{TT_recursion}
  \leanok
  $T_{m + 1} = 2T_{m}^2 - 1$, where $m \in \mathbb{N}$.
\end{lemma}
  
\begin{proof}
  \leanok
  Since $2^{m + 1} = 2 \times 2^m$, we can write $T_{m + 1} = T_{2 \times 2^m}$. It is already proven by induction in Mathlib (TODO: add succinct explanation) that a Chebyshev polynomial whose index is a product of integers can be written as a composition of two Chebyshev polynomials, so $T_{2 \times 2^m} = T_2 \circ T_{m}$. It follows from Definition \ref{def:T} that $T_2\left(r\right) = 2r^2 - 1$, so $T_2 \circ T_{m} = 2T_{m}^2 - 1 = T_{m + 1}$.
\end{proof}

\begin{lemma}[Bounds]
  \label{lem:bounds}
  $\TT[r]{m}^2 \leq 1$ if and only if $r^2 \leq 1$.
\end{lemma}
\begin{proof}
  Since $\TT[r]{0} = r$, having $r^2 \leq 1$ is necessary and sufficient when $m = 0$. Assume it holds for $m$, so that we can use Lemma \ref{lem:TT_recursion} to show it then holds for $\TT[r]{m + 1}^2 = \left(2\TT[r]{m}^2 - 1\right)^2$. Under the inductive hypothesis that $\TT[r]{m}^2 \leq 1$, then the entire right-hand side is less than one in magnitude. Conversely, if $\TT[r]{m}^2 > 1$, then the right-hand side remains greater than one in magnitude.
\end{proof}

\begin{lemma}[Fixed points]
  \label{lem:fixed_points}
  \lean{fixed_points}
  \uses{lem:TT_recursion}
  \leanok
  The only two fixed points of $2 \TT[r]{m}^2 - 1 \mapsto \TT[r]{m + 1}$ are $-\frac{1}{2}$ and $1$.
\end{lemma}

\begin{proof}
  \leanok
  If $\TT[r]{m + 1} = \TT[r]{m}$ under Lemma \ref{lem:TT_recursion}, then a quadratic equation, $2 \TT[r]{m}^2 - \TT[r]{m} - 1 = \left(2\TT[r]{m} + 1\right)\left(\TT[r]{m} - 1\right)  = 0$ whose only two solutions are $-\frac{1}{2}$ and $1$ defines the fixed points.
\end{proof}
\begin{remark*}
Both fixed points are repellent because the derivative of the mapping at a fixed point greater in magnitude than $1$. However, this has not been formalized yet since it is not a priority.
\end{remark*}
\noindent If either fixed point is reached, the remaining terms in $\varphi_k$ become a partial geometric series.
\begin{lemma}[Partial geometric series]
  \label{lem:geom_sum_neg_pow}
  If $b > 1$, then $\sum\limits_{m = j}^k b^{-m} = \frac{b^{1 - j} - b^{-k}}{b - 1}$.
\end{lemma}
\begin{proof}
  \leanok
  $\sum\limits_{m = j}^k b^{-m} = \sum\limits_{m = j}^k \left(\frac{1}{b}\right)^m \equiv S$, which is in the usual form of a geometric series with a ratio of $\frac{1}{b}$ whose partial sums are already proven in Mathlib. The usual method of proof is to note that since $S - \frac{1}{b} S = \sum\limits_{m = j}^k \left[\left(\frac{1}{b}\right)^m - \left(\frac{1}{b}\right)^{m + 1}\right] = \left(\frac{1}{b}\right)^j - \left(\frac{1}{b}\right)^{k + 1}$, then $S = \frac{\left(\frac{1}{b}\right)^j - \left(\frac{1}{b}\right)^{k + 1}}{1 - \frac{1}{b}} = \frac{b^{-j} - b^{-k - 1}}{\frac{b - 1}{b}} = \frac{b^{1 - j} - b^{-k}}{b - 1}$.
\end{proof}

\begin{lemma}[Symmetry]
  \label{lem:symmetry}
  $\TT[-r]{m} = \left(-1\right)^{2^m} \TT[r]{m}$.
\end{lemma}
\begin{proof}
  This also holds for Chebyshev polynomials whose index is not a power of two, but the general case is not yet proven in Mathlib, so we will prove it for $j = 2^m$. If $m = 0$, then $\TT[r]{0} = r$ so the claimed equation holds. Per the two-term recursion in Lemma \ref{lem:TT_recursion}, we need to show that $2\TT[-r]{m}^2 - 1 = \TT[-r]{m + 1} = \TT[r]{m + 1} = 2\TT[r]{m}^2 - 1$ because $\left(-1\right)^{2^m} = 1$ when $m > 0$.  Substituting for $\TT[-r]{m}$ with the inductive hypothesis implies $2\left[\left(-1\right)^{2^m} \TT[r]{m}\right]^2 - 1 =  2\TT[r]{m} - 1$.
\end{proof}

\begin{lemma}[Functional equation]
  \label{lem:functional_equation}
  $\varphi_k\left(-r\right) = \varphi_k\left(r\right) - r$.
\end{lemma}
\begin{proof}
  Per Lemma \ref{lem:symmetry}, the only term that differs in Definition \ref{def:core} between the $r$ and $-r$ cases is when $m = 0$ and $\frac{1}{2} 8^{0} \TT[\mp r]{0} = \frac{\mp r}{2}$. Thus, $\varphi_k\left(r\right) - \varphi_k\left(-r\right) = \frac{r}{2} - \frac{-r}{2} = r$.
\end{proof}
\begin{lemma}[Linearly shifted sum-of-squares]
  \label{lem:SOS}
  $\varphi_k\left(r\right) = \frac{5}{14} + \frac{8^{-k}}{7} + \frac{r}{2} + \frac{1}{8} \sum\limits_{m = 0}^{k - 1} 8^{-m} \TT[r]{m}^2$. 
\end{lemma}
\begin{proof}
Pull the $\TT[r]{0} = r$ term out of the series in Definition \ref{def:approx} and then shift the index of the summation while applying the two-term recursion from Lemma \ref{lem:TT_recursion} to all the remaining terms to obtain $\varphi_k\left(r\right) = \threesevenths + \offset + \frac{r}{2} + \frac{1}{2} \sum\limits_{m = 0}^{k - 1} 8^{-\left(m + 1\right)} \left(2 \TT[r]{m}^2 - 1\right)$. We can pull a factor of $\frac{1}{8}$ out of the sum and then separate it to obtain $\varphi_k\left(r\right) = \threesevenths + \offset + \frac{r}{2} + \frac{1}{8} \sum\limits_{m = 0}^{k - 1} 8^{-m} \TT[r]{m}^2 - \frac{1}{16} \sum\limits_{m = 0}^{k - 1} 8^{-m}$. Apply Lemma \ref{lem:geom_sum_neg_pow} with $b = 8$ to the last term and simplify the constant to obtain the claimed result.
\end{proof}

\renewcommand{\thetheorem}{\thesection.\arabic{theorem}}

\section{Convergence}\label{sec:Convergence}

\begin{lemma}
  \label{lem:convergence_characterization}
  Let $\mathbb{T} = \left[-1,1\right]$. If $t \in \mathbb{T}$, then the sequence of partial sums, $\{\varphi_k\left(t\right)\}$ forms a uniformly Cauchy sequence, but if $r \notin \mathbb{T}$, then the infinite sum in $\varphi\left(r\right)$ diverges.
\end{lemma}
\begin{proof}
  \uses{lem:TT_recursion, lem:geom_sum_neg_pow}
  \leanok
  To prove the if direction, we utilize the Weierstrass M-test, which is sufficient to prove that the sequence of partial sums forms a uniformly Cauchy sequence. Lemma \ref{lem:bounds} implies $\TT[t]{m} \in \mathbb{T}$. Since $\left|8^{-m} \TT[t]{m}\right| \leq 8^{-m}$ and $\frac{1}{2}\sum\limits_{m = 0}^\infty 8^{-m} = \frac{4}{7}$ by Lemma \ref{lem:geom_sum_neg_pow} with $b = 8$, $\varphi$ is well-defined on $\mathbb{T}$.

  To prove the only if direction, we utilize the last term test. It suffices to show that if $\left|r\right| > 1$, then the limit of $8^{-m} \TT[r]{m}$ as $m \uparrow \infty$ is not zero. When $r > 1$, it is already proven in Mathlib (TODO: add succinct explanation) that $T_j\left(r\right) = \cosh\left(j \theta\right)$ where $\theta$ is implicitly defined by $\cosh \theta = r$. Mathlib unfortunately lacks the $\cosh^{-1}$ function but has $\sinh^{-1}$, so we can explicitly define $\theta \equiv \sinh^{-1}\left(r^2 - 1\right) > 0$. Mathlib does prove that $\cosh\left(\sinh^{-1}\left(r^2 - 1\right)\right) = \sqrt{1 + r^2 - 1} = r > 1$. Moreover, $\cosh\left(2^m \theta\right) = \frac{e^{2^m \theta} - e^{-2^m \theta}}{2}$, so $\ln \frac{\TT[r]{m}}{2^{3m}} = 2^m \theta + \ln\left(1 + e^{-2^{m + 1} \theta}\right) - \left(3m + 1\right) \ln 2$. As $m \uparrow \infty$, a Maclaurin-series expansion of $\ln\left(1 + e^{-2^{m + 1} \theta}\right)$ reveals it approaches the negligibly small value of $e^{-2^{m + 1} \theta}$, and since $2^m \theta > 0$, it approaches $\infty$ as $m \uparrow \infty$ at a much faster rate than $-\left(3m + 1\right) \ln 2$ approaches $-\infty$. Thus, there is no limit of $8^{-m} \TT[r]{m}$ as $m \uparrow \infty$ when $r > 1$. When $r < -1$, Lemma \ref{lem:symmetry} shows that the only term in the infinite sum that changes is when $m = 0$ and $\TT[\mp r]{0} = \mp r$. Thus, the infinite sum also diverges when $r < -1$.
\end{proof}

\begin{remark*}
Since the error in approximating $\varphi\left(t\right)$ with $\varphi_k\left(t\right)$ is less than $\frac{2^{-3k}}{14}$, the approximation error if $k = 17$ is less than $\frac{2^{-52}}{7}$, where $2^{-52}$ is the smallest double-precision number that can be added to $1$ without underflow. Thus, only $18$ iterations of an unrolled loop with only a few floating-point operations per iteration are needed to recursively evaluate $\varphi_{17}\left(t\right)$ from Lemma \ref{lem:SOS}.
\end{remark*}
\begin{remark*}
  If $t = \frac{a}{b}$ where $a \in \mathbb{Z}$ and $b \in \mathbb{N}$ such that $\left|a\right| < b$ and $a$ has no common factor with $b$, then $\varphi_k\left(\frac{a}{b}\right)$ is also rational because the only operations in Definition \ref{def:core} are arithmetic. However, $\varphi\left(\frac{a}{b}\right)$ is generally irrational. The only five known rational values of $\varphi$ occur when one of the fixed points from Lemma \ref{lem:fixed_points} is quickly reached: $\varphi\left(1\right) = 1$ (implicit in Lemma \ref{lem:convergence_characterization}), $\varphi\left(-1\right) = \varphi\left(1\right) - 1 = 0$ (from Lemma \ref{lem:functional_equation}), $\varphi\left(-\frac{1}{2}\right) = \frac{3}{7} + \frac{1}{2} \sum\limits_{m = 0}^\infty 8^{-m} \left(-\frac{1}{2}\right) = \frac{1}{7}$ (from Lemmas \ref{lem:fixed_points} and \ref{lem:geom_sum_neg_pow}), $\varphi\left(\frac{1}{2}\right) = \varphi\left(-\frac{1}{2}\right) + \frac{1}{2} = \frac{9}{14}$ (from Lemma \ref{lem:functional_equation}), and $\varphi\left(0\right) = \frac{3}{7} + \frac{0}{2} - \frac{1}{8} + \frac{1}{2} \sum\limits_{m = 0}^\infty 8^{-m} = \frac{3}{8}$ (from Lemmas \ref{lem:fixed_points} and \ref{lem:geom_sum_neg_pow}). These five point coincide with the only five values where cosine and sine are rational according to Niven's theorem. Although the partial sums converge uniformly with an error bound proportional $\frac{1}{8^{k}}$, they do so with denominators that are too large for $\varphi\left(\frac{a}{b}\right)$ to be a Liouville number, so they may well be algebraic rather than transcendental. In addition, if $\TT[\frac{a}{b}]{m}$ is never either of the fixed points from Lemma \ref{lem:fixed_points}, then the numerators of the partial sums do not have a limit.
\end{remark*}

\begin{lemma}
  \label{lem:endpoint_singularities}
  $\varphi$ is not differentiable at $-1$ and $1$, which are essential logarithmic singularities.
\end{lemma}
\begin{proof}
  The derivative is defined as $\dot{\varphi}\left(t\right) \equiv \lim\limits_{h \rightarrow 0} \frac{\varphi\left(t + h\right) - \varphi\left(t\right)}{h}$. Per Lemma \ref{lem:convergence_characterization}, if $t + h \notin \mathbb{T}$, then this limit is undefined, which can occur if both $t = 1$ and $h > 0$ or if both $t = -1$ and $h < 0$. In other words, $\varphi$ is merely right differentiable at $t = 1$ and left differentiable at $t = -1$.
\end{proof}

\begin{proposition}[]
  \label{prop:q=0}
  \uses{def:core}
  If $q = 0$ or $q = 2n$, then $\psi_{p,q} \notin C^1\left(\mathbb{I}\right)$.
\end{proposition}
  
\begin{proof}
  \uses{lem:TT_recursion}
  Recall from Definition \ref{def:inner_function} that $\psi_{p,q}\left(x\right) \equiv \lambda_p \varphi\left(x - \frac{q}{2n}\right)$. Per Lemma \ref{lem:endpoint_singularities}, if $x + h - \frac{q}{2n} \notin \mathbb{T}$, then $\dot{\varphi}$ does not exist at that point and hence neither does $\dot{\psi}_{p,q}$ exist at that point. If $h > 0$, that exceptional case can occur if and only if both $x = 1$ and $q = 0$, and if $h < 0$, it can also occur if and only if both $x = 0$ and $q = 2n$.
\end{proof}
\begin{remark*}
Thus, our candidate for a core function narrowly avoids the fact proven by Vituskin and Khenkin that the KST would not hold if \emph{all} the inner functions were continuously differentiable.     
\end{remark*}
\begin{lemma}
  \label{lem:continuity}
  $\varphi \in C\left(\mathbb{T}\right)$.
\end{lemma}
\begin{proof}
  $\varphi_k$ in Definition \ref{def:approx} is a sum of polynomials and thus is continuous. Per Lemma \ref{lem:convergence_characterization}, $\{\varphi_k\}$ converges uniformly to $\varphi$ on $\mathbb{T}$. The uniform limit of a sequence of continuous functions is continuous, so $\varphi$ is continuous over $\mathbb{T}$ but no smoother in light of Lemma \ref{lem:endpoint_singularities}.
\end{proof}

\begin{lemma}
  \label{lem:end_continuity}
  If $q = 0$ or $q = 2n$, then $\psi_{p,q} \in C\left(\mathbb{I}\right)$.
\end{lemma}
\begin{proof}
  Recall from Definition \ref{def:inner_function} that $\psi_{p,q}\left(x\right) \equiv \lambda_p \varphi\left(x - \frac{q}{2n}\right)$, so Lemma \ref{lem:continuity} in fact implies $\psi_{p,q} \in C\left(\mathbb{I}\right)$ for any $p$ and $q$, but we will strengthen this for $0 < q < 2n$ below in Proposition \ref{prop:C2}.
\end{proof}

However, these last few results lack nuance because the derivative is undefined only at one or both endpoints of a domain, and the functions are quite smooth on the interior, as is shown in Figure \ref{fig:core}. Both $\varphi_{17}$ (in blue) and its derivative (in green) are are clearly increasing functions from $\mathbb{T}$ to $\mathbb{I}$. It appears that a small perturbation to $\varphi$ would violate one or more of our three requirements for a core function in the KSR (that are proven in Section \ref{sec:RequisiteProperties}): increasing over $\mathbb{T}$, not continuously differentiable over $\mathbb{T}$, and having a bounded derivative wherever it exists on $\mathbb{T}$. There may well be other ways to define a core function that has these three properties, but no one really has. Moreover, it seems difficult to construct one that converges more rapidly than $\varphi_k$ does. 
\begin{figure}
    \begin{center}
    \caption{The (well-approximated) core function and its derivative}
    \label{fig:core}
    \includegraphics[width=0.95\linewidth]{../images/core.png}
    \end{center}
    \emph{The blue line is for $\varphi_{17}$, which approximates $\varphi$ to double-precision. $\varphi_{17}$ is a polynomial of degree $2^{17} = 131,072$ whose exponents are all even numbers except for the linear term, which oscillates around a line almost $200$ times per pixel with amplitudes of about a quadrillionth. The green line is for the exact derivative of $\varphi_{17}$, which approximates the derivative of $\varphi$ on $\left(-1,1\right)$ in which case the latter exists, as is proven later in Lemma \ref{lem:functional_equation_deriv}. The black dotted line is for $\varphi_0$. The red points are discussed in Chapter \ref{ch:Injectivity} and are $\varphi\left(\tau\right)$ at Chebyshev-Lobatto nodes when $\tau = -\cos\frac{j\pi}{16}$ and $j$ is an integer between $0$ and $16$ inclusive. The two orange points are $\varphi\left(-\frac{1}{2}\right) = \frac{1}{7}$ and $\varphi\left(\frac{1}{2}\right) = \frac{9}{14}$, which along with the nodal values $\varphi\left(-1\right) = 0$, $\varphi\left(0\right) = \frac{3}{8}$, and $\varphi\left(1\right) = 1$ are the only five known rational values of $\varphi$ that are discussed in the second remark following Lemma \ref{lem:convergence_characterization}.}
\end{figure}

\section{Differentiability}\label{sec:Differentiability}

The fact that $\{\varphi_k\}$ converges uniformly to $\varphi$ per Lemma \ref{lem:convergence_characterization} does not, by itself, imply that $\{\dotvarphi{k}\}$ converges in any sense to $\dot{\varphi}$, in part because the derivative of $\varphi$ does not even exist at $-1$ and $1$ per Lemma \ref{lem:endpoint_singularities}. The purpose of this subsection is to establish rigorously that the intuition from the green line in Figure \ref{fig:core} holds on the open interval, $\left(-1,1\right)$, due to the uniform convergence of the derivatives, which can also be established using the Weierstrass M-test. Since $T_{2^m}$ and $\varphi_k$ are polynomials, their derivatives are also polynomials, although their limit as $k \uparrow \infty$ is not.

\begin{definition}[Chebyshev polynomial of the second kind]
  \label{def:U}
  \leanok
  The second-kind Chebyshev polynomial in $r$ with index $j \geq -1$ is defined recursively as
  \begin{align*}
U_j\left(r\right) \equiv 
\begin{cases}
0 & \text{if } j = -1 \\
1 & \text{if } j = 0 \\
2r & \text{if } j = 1 \\
2 r U_{j - 1}\left(r\right) - U_{j - 2}\left(r\right) & \text{if } j > 1
\end{cases}
  \end{align*}
\end{definition}

\begin{lemma}[]
  \label{lem:T_derivative}
  \uses{def:U}
  \leanok
  If $j \geq 0$, then $\dot{T}_j\left(r\right) = j U_{j - 1}\left(r\right)$.
\end{lemma}
\begin{proof}
  \leanok
  This is already proven by induction in Mathlib. TODO: Add a succinct explanation.
\end{proof}

\begin{lemma}
  \label{lem:U_composition}
  \uses{def:U, def:T}
  $U_{-1 + 2^{m + 1}}\left(r\right) = 2 \TT[r]{m} U_{-1 + 2^m}\left(r\right)$.
\end{lemma}
\begin{proof}
  Differentiate both sides of the two-term recursion from Lemma \ref{lem:TT_recursion} and utilize Lemma \ref{lem:T_derivative} to obtain $2^{m + 1} U_{-1 + 2^{m + 1}}\left(r\right) = 2^2\TT[r]{m} 2^m U_{-1 + 2^m}\left(r\right)$, and then divide both sides by $2^{m + 1}$.
\end{proof}

\begin{lemma}
  \label{lem:varphi_k_derivative}
  \uses{def:T, def:approx, def:U}
  $\dotvarphi[r]{k} = \frac{1}{2} \sum\limits_{m = 0}^k 4^{-m} U_{-1 + 2^m}\left(r\right)$.
\end{lemma}
\begin{proof}
  Applying Lemma \ref{lem:T_derivative} to each non-constant term in Definition \ref{def:approx} yields this result.
\end{proof}

\begin{lemma}
  \label{lem:derivative_convergence}
  If $t \in \mathbb{T}$, then the sequence of partial sums, $\{\dotvarphi[t]{k}\}$ forms a uniformly Cauchy sequence.
\end{lemma}
\begin{proof}
  We utilize the Weierstrass M-test, which is sufficient to prove that the sequence of partial sums forms a uniformly Cauchy sequence. If $m = 0$, then $U_0\left(t\right) = t$ has a minimum of $-1$ and a maximum of $1$. Per Lemma \ref{lem:bounds}, if $t \in \mathbb{T}$, then $\TT[t]{m} \in \mathbb{T}$, so Lemma \ref{lem:U_composition} indicates that the range of $U_{-1 + 2^{m + 1}}$ doubles with each $m$. Thus, $U_{-1 + 2^{m + 1}}$ has a minimum of $-2^m$ and a maximum of $2^m$. Since $\left|4^{-m} U_{-1 + 2^m}\right| \leq 2^{-m}$ and $\frac{1}{2}\sum\limits_{m = 0}^\infty 2^m = 1$ per Lemma \ref{lem:geom_sum_neg_pow} with $b = 2$, as $k \uparrow \infty$, $\{\dotvarphi[t]{k}\}$ converges uniformly on $\mathbb{T}$.
\end{proof}

\begin{lemma}
  \label{lem:weak_deriv}
  $\lim\limits_{k \uparrow \infty} \dot{\varphi}_k$ is a weak derivative of $\varphi$ that coincides with $\dot{\varphi}$ on $\left(-1,1\right)$. 
\end{lemma}
\begin{proof}
  The uniform convergence of $\{\dotvarphi[t]{k}\}$ in Lemma \ref{lem:derivative_convergence} justifies interchanging the limits in
  \begin{eqnarray*}
  \dotvarphi[t]{\infty} = \lim\limits_{h \rightarrow 0} \frac{\lim\limits_{k \uparrow \infty} \left[\varphi_k\left(t + h\right) - \varphi_k\left(t\right)\right]}{h} =
  \lim\limits_{k \uparrow \infty} \lim\limits_{h \rightarrow 0} \frac{\varphi_k\left(t + h\right) - \varphi_k\left(t\right)}{h} =
  \frac{1}{2} \sum\limits_{m = 0}^\infty 4^{-m} U_{-1 + 2^m}\left(t\right),
  \end{eqnarray*}
  where the last line follows from Lemma \ref{lem:varphi_k_derivative}. Per Lemma \ref{lem:convergence_characterization}, since $\{\varphi_k\left(t\right)\}$ converges to $\varphi\left(t\right)$ for at least one (actually all) value(s) of $t \in \mathbb{T}$, $\dot{\varphi}\left(t\right)$ exists on any proper \emph{subinterval} of $\mathbb{T}$.
\end{proof}

\begin{lemma}
  \label{lem:ODE}
  \uses{def:T, def:U}
  $\left(1 - r^2\right) \ddot{T}_{j}\left(r\right) - t \dot{T}_{j}\left(r\right) + j^2 T_j\left(r\right) = 0$.
\end{lemma}
\begin{proof}
  \uses{lem:TT_recursion}
  Although this lemma has been known for decades, it has not been formalized in Mathlib, so we follow the proof in Ponton. From Definition \ref{def:T}, if $j = 0$, then $T_0\left(r\right) = 1$, so $\dot{T}_0\left(r\right) = 0$ and $\ddot{T}_0\left(r\right) = 0$, which are consistent with the above Ordinary Differential Equation (ODE). Similarly, if $j = 1$, then $T_1\left(r\right) = t$ so $\dot{T}_1\left(r\right) = 1$ and $\ddot{T}_1\left(r\right) = 0$, which are also consistent with the above ODE.
  
  If $j > 1$, we can differentiate the three-term recursion, $T_j\left(r\right) = 2 r T_{j - 1}\left(r\right) - T_{j - 2}\left(r\right)$, to obtain
  \begin{eqnarray*}
    \dot{T}_j\left(r\right)  &=& 2 T_{j - 1}\left(r\right) + 2 r \dot{T}_{j - 1}\left(r\right) - \dot{T}_{j - 2}\left(r\right) \\
    \ddot{T}_j\left(r\right) &=& 4 \dot{T}_{j - 1}\left(r\right) + 2 r \ddot{T}_{j - 1}\left(r\right) - \ddot{T}_{j - 2}\left(r\right)
  \end{eqnarray*}
  If we substitute these three relations into the purported ODE and factor, we need to show that
  \begin{eqnarray*}
  0 &=& 2r \left[ \left(1 - r^2\right) \ddot{T}_{j - 1}\left(r\right) - r \dot{T}_{j - 1}\left(r\right) + \left(j - 1\right)^2 T_{j - 1}\left(r\right) \right] \\
    &-& \left[\left(1 - r^2\right) \ddot{T}_{j - 2}\left(r\right) - r \dot{T}_{j - 2}\left(r\right) + \left(j - 2\right)^2 T_{j - 2}\left(r\right)  \right] \\
    &+& 4 \left(j - 1\right) \left[\left(1 - r^2\right) U_{j - 2}\left(r\right) +  r T_{j - 1}\left(r\right) - T_{j - 2}\left(r\right)  \right].
  \end{eqnarray*}
  In each of the first two lines, the term in brackets is zero due to the inductive hypothesis, so we need to show that the term in brackets in the third line is also zero. It is already proven by induction in Mathlib (TODO: add succinct explanation) that $\left(1 - r^2\right) U_{j - 2}\left(r\right) = r T_{j - 1}\left(r\right) - T_{j}\left(r\right)$, so substituting and then expressing $T_{j}\left(r\right)$ via the three-term recursion yields the claimed result.
\end{proof}

\begin{lemma}
  \label{lem:varphi_k_derivative_derivative}
  \uses{def:approx, lem:varphi_k_derivative}
  If $t \in \left(-1,1\right)$, then $\ddotvarphi[t]{k} = \frac{t}{1 - t^2} \dotvarphi[t]{k} - \frac{1}{2\left(1 - t^2\right)} \sum\limits_{m = 0}^k 2^{-m} \TT[t]{m}$.
\end{lemma}
\begin{proof}
  \uses{lem:ODE, lem:weak_derivative, lem:geom_sum_neg_pow}
  Differentiate Definition \ref{def:approx} twice to obtain $\ddotvarphi[t]{k} = \frac{1}{2} \sum\limits_{m = 0}^k 8^{-m} \ddot{T}_{2^m}\left(t\right)$. Substitute inside the sum using Lemma \ref{lem:ODE} after isolating $\ddot{T}_{2^m}\left(t\right)$, and then simplify using Lemma \ref{lem:varphi_k_derivative}.
 \end{proof}

\begin{remark*}
  If $t^2 = 1$, then $\ddotvarphi[\mp 1]{k} = \frac{2^{k + 1} + 2^{-k} - 3}{6}$ by L'Hospital's rule, but this edge case is irrelevant.
\end{remark*}

\begin{lemma}
  \label{lem:more_convergence}
  If $t \in \left(-1,1\right)$, then the sequence of partial sums, $\{\ddotvarphi[t]{k}\}$ forms a uniformly Cauchy sequence.
\end{lemma}
\begin{proof}
  Lemma \ref{lem:derivative_convergence} establishes that $\dotvarphi[t]{k}$ in Lemma \ref{lem:varphi_k_derivative_derivative} converges uniformly on $\mathbb{T}$. The same proof of the ``if'' direction of Lemma \ref{lem:convergence_characterization} but now with $b = 2$ shows that the other sum also converges uniformly.
\end{proof}

\begin{lemma}
  \label{lem:weak_deriv_deriv}
  $\lim\limits_{k \uparrow \infty} \ddot{\varphi}_k$ is a weak second derivative of $\varphi$ that coincides with $\ddot{\varphi}$ on $\left(-1,1\right)$.
\end{lemma}
\begin{proof}
  The uniform convergence of $\{\ddotvarphi[t]{k}\}$ from Lemma \ref{lem:more_convergence} justifies interchanging the limits in
  \begin{eqnarray*}
  \ddotvarphi[t]{\infty} &=& \lim\limits_{h \rightarrow 0} \frac{\lim\limits_{k \uparrow \infty}\left[\dotvarphi[t + h]{k} - \dotvarphi[t]{k}\right]}{h} =
  \lim\limits_{k \uparrow \infty} \lim\limits_{h \rightarrow 0} \frac{\dotvarphi[t + h]{k} - \dotvarphi[t]{k}}{h} = \lim\limits_{k \uparrow \infty} \ddotvarphi[t]{k} \\
  &=& \frac{t}{1 - t^2} \dotvarphi[t]{\infty} + \frac{1}{2 \left(1 - t^2\right)} \sum\limits_{m = 0}^\infty 2^{-m} \TT[t]{m}.
  \end{eqnarray*}
  Since $\dot{\varphi}$ does not exist at $-1$ or $1$, neither does $\ddot{\varphi}$ exist at those two points. However, per Lemma \ref{lem:derivative_convergence}, since $\{\dotvarphi[t]{k}\}$ converges to $\dot{\varphi}\left(t\right)$ for at least one (actually all) value(s) of $t \in \left(-1,1\right)$, $\ddot{\varphi}_{\infty}$ coincides with $\ddot{\varphi}\left(t\right)$ on $\left(-1,1\right)$ and evaluates to the extended real number, $\infty$, if $t^2 = 1$.
\end{proof}

\begin{proposition}
  \label{prop:C2}
  If $0 < q < 2n$, then $\psi_{p,q} \in C^2\left(\mathbb{I}\right)$.
\end{proposition}
\begin{proof}
  Recall from Definition \ref{def:inner_function} that $\psi_{p,q}\left(x\right) \equiv \lambda_p \varphi\left(x - \frac{q}{2n}\right)$. If $0 < q < 2n$, then $x - \frac{q}{2n}$ cannot be $-1$ or $1$, in which case Lemma \ref{lem:more_convergence} implies that $\psi_{p,q}$ is twice differentiable.
\end{proof}
\begin{remark*}
  Proposition \ref{prop:C2} does not contravene the conclusion of Vitushkin and Khenkin that the KST cannot hold if \emph{all} the inner functions were continuously differentiable because Proposition \ref{prop:q=0} proves that if $q = 0$ or $q = 2n$, then $\psi_{p,q} \notin C^1\left(\mathbb{I}\right)$. Technicalities aside, our construction is much smoother than any other one in the KSR literature.
\end{remark*}
\begin{remark*}
  It seems implausible for $\varphi$ to have a third derivative over any proper subinterval of $\mathbb{T}$ because differentiating once more under the sum in Lemma \ref{lem:more_convergence} would yield a term, $\sum\limits_{m = 0}^\infty U_{-1 + 2^m}\left(t\right)$, that diverges unless $t$ is a root of some $U_{-1 + 2^m}$ and thus a root of $U_{-1 + 2^{m + 1}}$ per Lemma \ref{lem:U_composition}.
\end{remark*}
\begin{remark*}
  $\dotvarphi[t]{17}$ and $\ddotvarphi[t]{17}$ are less accurate near the endpoints of $\mathbb{T}$ than is $\varphi_{17}\left(t\right)$ due to the slower rates of convergence in the geometric series. But most numerical applications do not require extreme accuracy in the derivatives.
\end{remark*}


\section{Requisite Properties}\label{sec:RequisiteProperties}

This section merely proves what is already strongly suggested by Figure \ref{fig:core}, namely that $\varphi$ is weakly convex, strictly increasing, and a weak contraction.

\begin{lemma}
  \label{lem:functional_equation_deriv}
  $\dotvarphi[-r]{k} = 1 - \dotvarphi[r]{k}$.
\end{lemma}
\begin{proof}
  Differentiate both sides of the functional equation in Lemma \ref{lem:functional_equation}.
\end{proof}

\begin{lemma}
  \label{lem:functional_equation_deriv_deriv}
  $\ddotvarphi[-r]{k} = \ddotvarphi[r]{k}$.
\end{lemma}
\begin{proof}
  Differentiate both sides of the functional equation in Lemma \ref{lem:functional_equation_deriv}.
\end{proof}

\begin{lemma}
  \label{lem:strictly_convex}
  If $k > 0$, then $\varphi_k$ is a strictly convex function over $\mathbb{T}$, and if $k = 0$, then $\varphi_0$ is weakly convex over $\mathbb{T}$.
\end{lemma}
\begin{proof}
  A twice-differentiable function, such as $\varphi_k$, is strictly convex on $\mathbb{T}$ if and only if its second derivative is positive on $\mathbb{T}$. Suppose on the contrary that $\ddotvarphi[t]{k} = 0$ for some $t \in \mathbb{T}$. Since $\ddot{\varphi}_k$ is an even function per Lemma \ref{lem:functional_equation_deriv_deriv}, $\ddotvarphi[-t]{k} = 0$ as well. Subtracting the latter equation from the former using the expression for the second derivative in Lemma \ref{lem:varphi_k_derivative_derivative} implies $\frac{t}{1 -t^2} \dotvarphi[t]{k} - \frac{-t}{1 - t^2} \dotvarphi[-t]{k} = \frac{1}{2 \left(1 - t^2\right)} \sum\limits_{m = 0}^k 2^{-m} \left(\TT[t]{m} - \TT[-t]{m}\right)$. The left-hand side simplifies to $\frac{t}{1 - t^2}$ under Lemma \ref{lem:functional_equation_deriv}, while the right-hand side also simplifies to $\frac{t}{1 - t^2}$ under Lemma \ref{lem:symmetry}. Together that implies that $\ddot{\varphi}_k$ would be a horizontal line at zero, which is actually the case when $k = 0$ and $\varphi_0\left(t\right) = \frac{1 + t}{2}$ is a line segment. If $k > 0$ and $t = 0$, then Lemma \ref{lem:varphi_k_derivative_derivative} implies $\ddotvarphi[0]{k} = \frac{0}{1} \dotvarphi[0]{k} - \frac{1}{2}\left(0 - \frac{1}{2} + \sum\limits_{m = 2}^k 2^{-m}\right) = 2^{-k - 1} > 0$, where the last equality follows from Lemma \ref{lem:geom_sum_neg_pow} with $b = 2$. This example contradicts the premise that $\ddot{\varphi}_k$ is a horizontal line at zero when $k > 0$ and a certifies that the second derivative is strictly positive  over $\mathbb{T}$ rather than strictly negative.
\end{proof}
\begin{lemma}
  \label{lem:weakly_convex}
  \uses{def:core}
  $\varphi$ is a weakly convex function over $\mathbb{T}$.
\end{lemma}
  
\begin{proof}
  \uses{lem:TT_recursion}
  Per Lemma \ref{lem:strictly_convex}, $\varphi_k$ is a strictly convex when $k > 0$, and per Lemma \ref{lem:convergence_characterization} $\{\varphi_k\}$ converges uniformly to $\varphi$. The uniform limit of a sequence of strictly convex functions is at least a weakly convex function. Although $\lim\limits_{k \uparrow \infty} 2^{-k - 1} = 0$ and $\ddot{\varphi}\left(0\right) = 0$ is an inflection point, $\ddot{\varphi}$ can never be negative on $\mathbb{T}$, so $\varphi$ is weakly convex.
\end{proof}

\begin{lemma}[]
  \label{lem:derivative_bounds}
  \uses{lem:varphi_k_derivative}
   If $t \in \mathbb{T}$, then $2^{-k - 1} \leq \dotvarphi[t]{k} \leq 1 - 2^{-k - 1}$.
\end{lemma}
\begin{proof}
  Per Lemma \ref{lem:strictly_convex}, $\varphi_k$ is strictly convex when $k > 0$, so its derivative in Lemma \ref{lem:varphi_k_derivative} is an increasing function over $\mathbb{T}$ that is minimized at $t = -1$ and maximized at $t = 1$ (which is also true if $k = 0$). It is already proven by induction in Mathlib that $U_j\left(-1\right) = \left(-1\right)^j \left(j + 1\right)$, which is apparent from Definition \ref{def:U}. Per Lemma \ref{lem:varphi_k_derivative}, $\dotvarphi[-1]{k} = \frac{1}{2} - \frac{1}{2} \sum\limits_{m = 1}^k 4^{-m} 2^m = \frac{1}{2} - \frac{1}{2} \sum\limits_{m = 1}^k 2^{-m} = 2^{-k - 1}$ by Lemma \ref{lem:geom_sum_neg_pow} with $b = 2$. Lemma \ref{lem:functional_equation_deriv} then implies $\dotvarphi[1]{k} = 1 - 2^{-k - 1}$.
\end{proof}

\begin{lemma}
  \label{lem:increasing}
  \uses{def:core}
  $\varphi$ is a strictly increasing function over $\mathbb{T}$.
\end{lemma}

\begin{proof}
  \uses{lem:derivative_bounds, lem:limit}
  Per Lemma \ref{lem:derivative_bounds}, $\varphi_k$ is a strictly increasing function over $\mathbb{T}$, and per Lemma \ref{lem:convergence_characterization} $\{\varphi_k\}$ converges uniformly to $\varphi$. The uniform limit of strictly increasing functions is a strictly increasing function, so $\varphi$ is a strictly increasing function.
\end{proof}

\begin{lemma}
  \label{lem:contraction}
  \uses{def:core}
  $\varphi$ is a weak contraction over $\mathbb{T}$.
\end{lemma}

\begin{proof}
  \uses{lem:derivative_bound, lem:limit}
  Lemma \ref{lem:derivative_bounds} implies $\varphi_k$ is Lipschitz continuous with a constant of $1 - 2^{-k - 1}$, and per Lemma \ref{lem:convergence_characterization} $\{\varphi_k\}$ converges uniformly to $\varphi$. The uniform limit of Lipschitz continuous functions is Lipschitz continuous. Although the derivative of $\varphi$ does not exist at $t = 1$, the supremum of the derivative of $\varphi$ is $1$, making it a weak contraction on $\mathbb{T}$.
\end{proof}

\begin{lemma}
  \label{lem:range}
  \uses{def:approx, def:core}
  If $t \in \mathbb{T}$, then $0 \leq \varphi_k\left(t\right) \leq 1$.
\end{lemma}

\begin{proof}
  \uses{lem:convexity, lem:fixed_points, lem:geom_sum_neg_pow, lem:TT_recursion}
  Per Lemma \ref{lem:derivative_bounds}, $\varphi_k$ is a strictly increasing function over $\mathbb{T}$, which is minimized at $t = -1$ and maximized at $t = 1$.
  If $t = 1$, Lemma \ref{lem:fixed_points} implies $\TT[1]{m} = 1$. Thus, Definition \ref{def:approx} specializes to $\varphi_k\left(1\right) = \threesevenths + \offset + \frac{1}{2} \sum\limits_{m = 0}^k 8^{-m} = \threesevenths + \offset + \frac{8 - 8^{-k}}{14} = 1$ by Lemma \ref{lem:geom_sum_neg_pow} with $b = 8$. Lemma \ref{lem:functional_equation} then implies $\varphi_k\left(-1\right) = 0$.
\end{proof}
\noindent Hence, the unusual constant, $\offset$, in Definition \ref{def:approx} anchors its range to be the same for all $k$.

\begin{lemma}
  \label{lem:range_limit}
  If $t \in \mathbb{T}$, then $0 \leq \varphi\left(t\right) \leq 1$.
\end{lemma}
\begin{proof}
    Since the bounds on $\varphi_k$ in Lemma \ref{lem:range} do not depend on $k$, they are preserved as $k \uparrow \infty$.
\end{proof}

This chapter has demonstrated that our construction threads a needle. Lemma \ref{lem:endpoint_singularities} states that $\varphi$ is technically not continuously differentiable over $\mathbb{T}$, but only because it has essential singularities at both endpoints of $\mathbb{T}$. Thus, it is more useful to focus on the facts that $\varphi$ is twice differentiable on $\left(-1,1\right)$ per Lemma \ref{lem:weak_deriv_deriv} and can be uniformly approximated by high-degree polynomials per Lemma \ref{lem:convergence_characterization}. Thus, from a numerical perspective, $\varphi$ is no different from the inverse trigonometric functions that are implemented in standard libraries, in the sense that they can be approximated to machine precision and the lack of a derivative at two or three points is a minor inconvenience.

\chapter{Injectivity}\label{ch:Injectivity}

The goal of this chapter is to prove that $\boldsymbol{\Psi}$ is an injective function on $\mathbb{I}^n$ for some $\lambda > 0$.

\begin{definition}
  \label{def:Psi_vector}
  Let $\boldsymbol{\Psi}\left(\mathbf{x}\right) \equiv \begin{bmatrix}
      \Psi_0\left(\mathbf{x} - 0\right) \\
      \Psi_1\left(\mathbf{x} - \frac{1}{2n}\right) \\
      \vdots \\
      \Psi_q\left(\mathbf{x} - \frac{q}{2n}\right) \\
      \vdots \\
      \Psi_{2n}\left(\mathbf{x} - 1\right)
  \end{bmatrix}$ be a column vector of size $2n + 1$, where $\mathbf{x}^\top = \begin{bmatrix}
      x_0 \\ x_1 \\ \vdots \\ x_p \\ \vdots \\ x_{n - 1}
  \end{bmatrix}$ is a column vector of size $n$ that holds the arguments to $f$, and $\Psi_q\left(\mathbf{x} - \frac{q}{2n}\right) \equiv \sum\limits_{p = 0}^{n - 1} \frac{\lambda^p}{\Lambda} \varphi\left(x_p - \frac{q}{2n}\right)$ in our construction from Chapter \ref{ch:CoreFunction}.
\end{definition}

\begin{figure}
    \begin{center}
    \caption{Some level sets of $\Psi_q\left(\begin{bmatrix} x_1 & x_2\end{bmatrix}\right)$ when $n = 2$ and $\lambda = 2\pi - 1$}
    \label{fig:injective}
    \includegraphics[width=0.95\linewidth]{../images/injective.png}
    \end{center}
    \emph{Each contour line is a level set, albeit at a different value of $x$, where $\Psi_q\left(\begin{bmatrix} x_1 & x_2 \end{bmatrix}\right) = \varphi\left(x - \frac{q}{2n}\right)$.}
\end{figure}

When $n = 2$, we can illustrate the issue as in Figure \ref{fig:injective}. For each of the five values of $q$, contour lines are plotted that depict pairs of values for $x_1$ and $x_2$ where $\Psi_q\left(\begin{bmatrix} x_1 & x_2 \end{bmatrix}\right) = \varphi\left(x - \frac{q}{2n}\right)$ for various values of $x$. Sprecher's mechanism of shifting $x_p$ by $-\frac{q}{2n}$ ensures that these contour lines are largely parallel to each other. Pairs of contour lines can and do intersect, but the KST cannot hold if all $2n + 1$ functions intersect at the same $\mathbf{x}$. There are an infinite number of level sets, each corresponding to a different value of $x$, so it is impossible to determine visually whether this condition is met. However, at the top right of the last plot, these contour lines are compressed into a small region, so the exact nature of the curvature there is important.

The contour lines are downward sloping and cross the diagonal, which justifies thinking of a level set as all possible vectors $\mathbf{x}$ that render $\Psi_q\left(\mathbf{x}\right)$ equal to $\varphi\left(x - \frac{q}{2n}\right)$, which is the value that $\Psi_q$ would take if all its arguments were equal to $x$. Sprecher
\begin{quote}
What this says about the superposition representation of an arbitrary continuous function $f\left(x_1, x_2\right)$ is that it is determined at five points on the diagonal through its representation \dots
The first thing to notice is the relation between the level sets of superpositions and target functions. An arbitrary function $f\left(x_1, x_2\right)$ may have infinitely many values on one or or more level sets \dots But on these the functions $\left[\Psi_q\right]$ can only compute one value of $f$. [78 - 79]
\end{quote}

\section{Linear Algebra}\label{sec:LinearAlgebra}

\begin{definition}[Weak Jacobian matrix]
  \label{def:J}
  Let $\mathbf{J}\left(\mathbf{x}\right)$ be a matrix with $2n + 1$ rows and $n$ columns such that each element is $J_{q,p} \equiv \lambda_p \dotvarphi[x_p - \frac{q}{2n}]{\infty} = \frac{\lambda^p}{2\Lambda} \sum\limits_{m = 0}^\infty 4^{-m} U_{-1 + 2^m}\left(x_p - \frac{q}{2n}\right)$ per Lemma \ref{lem:weak_deriv}.
\end{definition}
\begin{remark*}
  $\mathbf{J}\left(\mathbf{x}\right)$ in Definition \ref{def:J} can be evaluated at a point in $\mathbb{I}^n$ even when $\frac{\partial \Psi_q}{\partial x_p}$ is not defined, which occurs either when both $x_p = 1$ and $q = 0$ or when both $x_p = 0$ and $q = 2n$. Otherwise, $\mathbf{J}\left(\mathbf{x}\right)$ is a traditional Jacobian matrix because the weak derivative coincides with the derivative.
\end{remark*}

\begin{lemma}
  \label{lem:full_rank}
  $\mathbf{J}\left(\mathbf{x}\right)$ has full column rank for all $\mathbf{x} \in \mathbb{I}^n$.
\end{lemma}
\begin{proof}
  The $p$-th column of $\mathbf{J}\left(\mathbf{x}\right)$ is a nonlinear function only of $x_p$, so it is impossible to express any column as an exact linear function of the other columns.
\end{proof}

\begin{proposition}
  $\boldsymbol{\Psi}$ is an injective function on $\mathbb{I}^n$ for any $\lambda > 0$
\end{proposition}
\begin{proof}
  Lemma \ref{lem:full_rank} suffices to prove that $\boldsymbol{\Psi}$ is \emph{locally} injective throughout the interior of $\mathbb{I}^n$. Thus, we only need to rule out some global and boundary concerns. Per Lemma \ref{lem:contraction}, $\varphi$ is Lipschitz continuous and so is each $\psi_{p,q}$. Lipschitz continuous functions are absolutely continuous and so the Fundamental Theorem of Calculus applies. Suppose on the contrary that $\boldsymbol{\Psi}\left(\mathbf{x}\right) = \boldsymbol{\Psi}\left(\mathbf{x}^\prime\right)$ but $\mathbf{x} \neq \mathbf{x}^\prime$. There is a smooth path between $\mathbf{x}$ and $\mathbf{x}^\prime$. Integrating the directional derivatives along that path should yield a value zero, but cannot be zero since $\mathbf{J}\left(\mathbf{x}\right)$ has full column rank.
\end{proof}
\begin{remark*}
  I am not entirely sure how the details of the previous ``proof'' would work, so below is another proof that is very consistent with the KST literature.
\end{remark*}

\section{Trigonometric Representation}\label{sec:TrigonometricRepresentation}

\begin{lemma}[]
  \label{lem:trigonometric}
  \uses{def:T}
  \leanok
  If $t \in \mathbb{T}$, then $T_j\left(t\right) = \cos\left(j \cos^{-1}t\right)$.
\end{lemma}
  
\begin{proof}
  \leanok
  This lemma has been known for decades and is already proven in Mathlib. Let $t = \cos \theta$. If $j = 0$, then $T_0\left(t\right) = 1 = \cos\left(0 \theta\right)$. If $j = 1$, then $T_1\left(t\right) = t = \cos\left(1 \theta\right)$. It remains to show for $j > 1$ that the three-term recursion from Definition \ref{def:T} is satisfied: $T_j\left(t\right) = 2 \cos \theta \cos\left(\left(j - 1\right) \theta\right) - \cos\left(\left(j - 2\right) \theta\right)$. The first term can be rewritten as $2\cos \theta \cos\left(\left(j - 1\right) \theta\right) = \cos\left(\theta - \left(j - 1\right)\theta\right) + \cos\left(\theta + \left(j - 1\right)\theta\right) = \cos\left(\left(j - 2\right)\theta\right) + \cos\left(j \theta\right)$, so $T_j\left(t\right) = \cos\left(j \theta\right)$.
\end{proof}

\begin{remark*}
Under Definition \ref{def:core} and Lemma \ref{lem:trigonometric}, $\threesevenths + \frac{1}{2} \sum\limits_{m = 0}^\infty \left(\frac{1}{8}\right)^{m} \cos\left(2^m \theta\right)$ resembles the function, $w\left(y\right) = \sum\limits_{m = 0}^\infty \alpha^m \cos\left(\beta^m \pi y\right)$, Weierstrass proved to be nowhere differentiable when $\beta \geq 7$ also satisfies $\alpha \beta > 1 + \frac{3}{2} \pi$ for $0 < \alpha < 1$. But the terms in our $\varphi$ have less extreme oscillation, smaller amplitudes, and another composition, so $\varphi$ merely has essential singularities at the endpoints of $\mathbb{T}$.
\end{remark*}

\begin{lemma}[Chebyshev-Lobatto nodes]
  \label{lem:nodes}
  The $1 + 2^k$ extrema of $T_{2^k}$ are called (Chebyshev-Lobatto) nodes and occur at $\tau = -\cos\frac{j\pi}{2^k}$ with $0 \leq j \leq 2^k$ and $k \in \mathbb{N}$.
\end{lemma}
\begin{proof}
  \uses{lem:trigonometric}
  If $\tau = -\cos\frac{j\pi}{2^k}$, then $\TT[\tau]{k} = \cos\left(2^k \cos^{-1}\left(\cos \frac{-j\pi}{2^k}\right)\right) = \cos\left(-j\pi\right)$. If $j$ is even, $\TT[\tau]{k} = 1$ and if $j$ is odd $\TT[\tau]{k} = -1$.
\end{proof}
The function approximation literature also defines nodes when the index of the Chebyshev polynomial is not a power of two, but we only consider the case where $\tau = -\cos\frac{j\pi}{2^k}$. It is essential to recognize that if $\tau = -\cos\frac{j\pi}{2^k}$, then it is also true that $\tau = -\cos\frac{\left(2j\right)\pi}{2^{k + 1}}$. Thus, a node at iteration $k$ is also a node at iteration $k + 1$ but with an index that is double its previous index.

\begin{definition}[$\gamma$-nodes]
  \label{def:gamma_nodes}
  Let $\gamma = -\cos\frac{\left(3j + 1\right)\pi}{2^{k - 1} \times 3}$ for some $0 \leq j \leq 2^{k - 1}$ and $k > 0$.
\end{definition}

The orange points in Figure \ref{fig:core} are the values of $\varphi\left(\mp \frac{1}{2}\right)$, whose argument $-\cos\frac{\pi}{3} = -\frac{1}{2}$ and $-\cos\frac{2\pi}{3} = \frac{1}{2}$ is a $\gamma$-node when $k = 1$; see the second remark following Lemma \ref{lem:convergence_characterization}. The red points in Figure \ref{fig:core} are the values of $\varphi$ at Chebyshev-Lobatto nodes when $k = 4$, which crucially can be calculated \emph{exactly} in a finite number of arithmetic operations from $\varphi_4$ or better.

\begin{lemma}[Zero approximation error]
  \label{lem:magic}
  \uses{def:approx, def:core}
  If $\tau = -\cos\frac{j\pi}{2^k}$, then $\varphi_k\left(\tau\right) = \varphi\left(\tau\right)$.
\end{lemma}
\begin{proof}
  \uses{lem:fixed_points, lem:geom_sum_neg_pow}
  If $\tau = -\cos\frac{j\pi}{2^k}$, then Lemma \ref{lem:nodes} implies $\TT[\tau]{k} = \mp 1$, and Lemma \ref{lem:fixed_points} implies $\TT[\tau]{k + 1} = 1$ is a fixed point. By Lemma \ref{lem:geom_sum_neg_pow} with $b = 8$, $\varphi\left(\tau\right) = \threesevenths + \halfsum{0}{k}{\tau} + \frac{1}{2}\sum\limits_{m = k + 1}^\infty 8^{-m} = \threesevenths + \halfsum{0}{k}{\tau} + \offset = \varphi_k\left(\tau\right)$. Thus, the first-order correction, $\offset$, is exact when $\tau$ is a node.
\end{proof}

\section{Number Theory}\label{sec:NumberTheory}

\begin{lemma}
  \label{lem:extrema}
  If $\tau = -\cos\frac{j\pi}{2^k}$ for some $0 < j < 2^k$, then $\tau$ is a root of $U_{-1 + 2^k}$.
\end{lemma}
\begin{proof}
  Standard using Lemma \ref{lem:T_derivative}; extrema of polynomials are roots of their derivatives.
\end{proof}

\begin{definition}[Cyclotomic polynomial of order $2^m$]
  Let $m > 0$ be an integer. The $2^m$-th cyclotomic polynomial is the irreducible polynomial, $\Phi_{2^m}\left(r\right) \equiv r^{2^{m - 1}} - 1$.
\end{definition}

\begin{lemma}
  \label{lem:factorization}
  If $k > 0$, then $U_{-1 + 2^k}\left(r\right) = \prod\limits_{m = 1}^k \Phi_{2^m}\left(r\right)$.
\end{lemma}
\begin{proof}
  It can be done by induction.
\end{proof}
\begin{remark*}
$U_{-1 + 2^k}$ factors into a product of irreducible polynomials, each of which only has complex roots, but their real parts are the roots of $U_{-1 + 2^k}$.
\end{remark*}
\begin{definition}[Cyclotomic field]
  A cyclotomic field is an extension of the field of rational numbers, $\mathbb{Q}$, that is formed by adjoining some complex root, $\zeta$, of a cyclotomic polynomial.
\end{definition}

\begin{definition}[Maximal real cyclotomic extension of $\mathbb{Q}$ for power-of-2 roots of unity]
  \label{def:F}
  Let $\mathbb{F}_\tau \equiv \mathbb{R} \bigcap \bigcup\limits_{k = 1}^\infty \mathbb{Q}\left(\zeta_{2^k}\right)$, where $\zeta_{2^k}$ is some root of $\Phi_{2^k}$.
\end{definition}

\begin{lemma}
  \label{lem:injective}
  \uses{def:Psi_q, def:F}
  If $\lambda \notin \mathbb{F}_\tau$, then $\Psi_q$ is an injective function on $\left(\mathbb{F}_\tau \bigcap \mathbb{I}\right)^n$.
\end{lemma}
\begin{proof}
  \uses{lem:magic}
  Let each $x_p - \frac{q}{2n}$ and $x_p^\prime - \frac{q}{2n}$ be a member of $\mathbb{F}_\tau \bigcap \mathbb{I}$. Suppose $\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right) = \Psi_q\left(x_1^\prime, x_2^\prime, \dots, x_n^\prime\right)$ and rearrange this condition as
  \begin{eqnarray*}
      \frac{\varphi\left(x_0 - \frac{q}{2n}\right) - \varphi\left(x_0^\prime - \frac{q}{2n}\right)}{\Lambda} &=& \frac{\sum\limits_{p = 1}^{n - 1}\lambda^p \left[\varphi\left(x_p^\prime - \frac{q}{2n}\right) - \varphi\left(x_p - \frac{q}{2n}\right)\right]}{\Lambda}.
  \end{eqnarray*}  
  Suppose, on the contrary, that $\Psi_q$ is not injective, which is to say that the above equation has a non-trivial solution. Then, the Mean Value Theorem states for a function like $\varphi$ that is continuous on a closed interval (per Lemma \ref{lem:continuity}) and differentiable on the open interval that excludes its endpoints (per Lemma \ref{lem:weak_deriv}), there exists a $t_0$ strictly between $x_0 - \frac{q}{2n}$ and $x_0^\prime - \frac{q}{2n}$ such that $\varphi\left(x_0 - \frac{q}{2n}\right) - \varphi\left(x_0^\prime - \frac{q}{2n}\right) = \left[x_0 - \frac{q}{2n} - x_0^\prime + \frac{q}{2n}\right] \dot{\varphi}\left(t_0\right)$. Moreover, $t_0$ is unique in this case because $\varphi$ is a strictly increasing function on $\mathbb{T}$ per Lemma \ref{lem:increasing}. After canceling the $\Lambda$ from the above equation, substituting with the Mean Value Theorem, and dividing both sides by $\dot{\varphi}\left(t_0\right)$, we obtain
  \begin{eqnarray*}
      x_0 - x_0^\prime &=& \frac{1}{\dot{\varphi}\left(t_0\right)}\sum\limits_{p = 1}^{n - 1}\lambda^p \left[\varphi\left(x_p^\prime - \frac{q}{2n}\right) - \varphi\left(x_p - \frac{q}{2n}\right)\right].
  \end{eqnarray*}
  The left-hand side is a member of $\mathbb{F}_\lambda$, which cannot be equal to the right-hand side when $\lambda \notin \mathbb{F}_\tau$ because the latter is a member of $\mathbb{F}_\tau\left(\lambda, \dot{\varphi}\left(t_0\right)\right) / \mathbb{F}_\tau$. Thus, there is only a trivial solution to the original equation where $x_p = x_p^\prime$ for all $p$, which characterizes an injective function.
\end{proof}

\begin{remark*}
  Suppose $x_p - \frac{q}{2n} = -\cos \frac{j\pi}{2^k}$ and $x_p^\prime - \frac{q}{2n} = -\cos \frac{j^\prime\pi}{2^k}$, in which case the Mean Value Theorem implies there is a (in this case unique) $t_p$ strictly between $x_p - \frac{q}{2n}$ and $x_p^\prime - \frac{q}{2n}$ such that $\left[x_p - x_p^\prime\right]\dot{\varphi}\left(t_p\right) = \varphi_k\left(x_p - \frac{q}{2n}\right) - \varphi_k\left(x_p^\prime - \frac{q}{2n}\right)$, where we have used Lemma \ref{lem:magic} to substitute $\varphi_k$ for $\varphi$. Although $\dot{\varphi}\left(t_p\right) \in \mathbb{F}_\tau$ because $x_p - x_p^\prime \in \mathbb{F}_\tau$ and $\varphi_k\left(x_p - \frac{q}{2n}\right) - \varphi_k\left(x_p^\prime - \frac{q}{2n}\right) \in \mathbb{F}_\tau$, it seems that $t_p \notin \mathbb{F}_\tau$ when $k > 1$. Thus, $\dotvarphi{k}$ can somehow map some foreign numbers in $\mathbb{T}$ into $\mathbb{F}_\tau$.
\end{remark*}

\begin{proposition}
For some $\lambda > 0$, $\boldsymbol{\Psi}$ is an injective function on $\mathbb{I}^n$.    
\end{proposition}
\begin{proof}
The fact that $\boldsymbol{\Psi}$ is injective on a dense set, $\left(\mathbb{F}_\tau \bigcap \mathbb{I}\right)^n$, and is both convex (since it is a weighed sum of convex inner functions) and continuous allows us to do a proof by contradiction.
\end{proof}

%\begin{lemma}
%  \label{lem:dense}
%  Chebyshev-Lobatto nodes are dense in $\mathbb{T}$.
%\end{lemma}
%\begin{proof}
%  First note that $\int\limits_{-1}^1 \frac{1}{\pi \sqrt{1 - t^2}} dt = \frac{\sin^{-1}\left(1\right)}{\pi} + \frac{1}{2} - \frac{\sin^{-1}\left(-1\right)}{\pi} - \frac{1}{2} = 1$, so $\frac{\sin^{-1} t}{\pi} + \frac{1}{2}$ can be interpreted as a Cumulative Density Function that yields the probability of a random variable whose sample space is $\mathbb{T}$ being less than or equal to $t$. Since $\sin\left(\frac{\pi}{2} - y\right) = \cos y$, $\sin^{-1}\left(\cos y\right) = \frac{\pi}{2} - y$. If $\tau = \cos \frac{-j\pi}{2^k}$ for some $0 \leq j \leq 2^k$, then $\frac{\sin^{-1}\left(\tau\right)}{\pi} + \frac{1}{2} = 1 - \frac{j}{2^k}$ is the probability of a node being less than or equal to $\cos\frac{-j\pi}{2^k}$. By symmetry $\frac{j}{2^k}$ is the probability of a node being less than or equal to $-\cos \frac{j\pi}{2^k}$, the Probability Density Function for nodes is $\frac{1}{\pi \sqrt{1 - t^2}} > 0$, and a random node can be obtained by applying the sine function to a uniform random variate between $-\frac{\pi}{2}$ and $\frac{\pi}{2}$.
%\end{proof}

\chapter{Outer Functions}\label{ch:OuterFunctions}

This chapter currently contains some disconnected fragments of thoughts.

Kahane proves that if there were fewer than $2n + 1$ rows in the output, then almost no mapping from $\mathbb{I}^n$ would be injective and thus the KST would not hold, which is a result that is usually credited to Sternfeld a few years later. In addition, Whitney previously proved that a smooth mapping from a space of dimension $n$ to a space of dimension $2n + 1$ can be further embedded into a space of dimension $2n$, which provides some intuition for Vitushkin and Khenkin's result that the KST cannot hold if all the inner functions were continuously differentiable.

Kaufman proves a mercifully short proof that the KST cannot hold if the genuine Jacobian matrix is of full rank, but this proof presumes on the equicontinuity of the inner functions, which does not hold in our case because $\psi_{p,q} \notin C^1\left(\mathbb{I}\right)$ if $q = 0$ or $q = 2n$ (per Proposition \ref{prop:q=0}), while $\psi_{p,q} \in C^2\left(\mathbb{I}\right)$ otherwise (per Proposition \ref{prop:C2}). So, the question becomes is equicontinuity actually necessary for Kaufman's theorem?

The number of distinct outer functions can also be reduced to one by shifting the argument.
\begin{definition}
  \label{def:outer}
  $\chi_q\left(\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right)\right) \equiv \chi\left(\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right) + q\right)$.
\end{definition}

Kahane's geometric interpretation of the KST goes like this. Let $\Gamma_p$ denote an ``increasing curve'' in $\mathbb{R}^{2n + 1}$ for the equation $X_q\left(x\right) = \lambda_p \varphi\left(x - \frac{q}{2n}\right)$. Let $E \equiv \lambda_1 \Gamma + \lambda_2 \Gamma + \dots + \lambda_n \Gamma$, so $E \subset \mathbb{I}^{2n + 1}$. Then,
\begin{enumerate}
  \item The mapping $\Gamma_1 \times \Gamma_2 \times \dots \times \Gamma_n$ is injective so $E$ is a distorted cube
  \item $E$ is an interpolation set in the sense that every continuous function on can be written in the form $\chi_1\left(X_1\right) + \chi_2\left(X_2\right) + \dots + \chi_{2n}\left(X_{2n}\right)$.
\end{enumerate}

\begin{definition}[Helson set]
  \label{def:Helson_set}
``[A] Helson set in a locally compact abelian group $G$ is a closed set $E$ such that the algebra $A(E)$ of restrictions to $E$ of functions in $A(G)$ (Fourier transforms of summable functions on the dual group) coincides with $C(E)$, the algebra of all continuous functions on $E$." (translated from page 91 of Kahane 1978) 
\end{definition}

\begin{lemma}
  \label{lem:not_Helson}
  \uses{def:Helson_set}
  ``If $E$ contains the algebraic sum of two infinite sets, $E$ is not a Helson set.''
\end{lemma}
\begin{proof}
  See page 91 of Kahane 1978; it has to do with violating a mesh condition.
\end{proof}

\begin{lemma}
  \label{lem:polynomial}
  \uses{def:Helson_set}
  If $\gamma$ coincides on any subinterval of $\mathbb{I}$ with a polynomial of degree less than $n$, then $\{\gamma\left(\Psi_1\right), \gamma\left(\Psi_2\right), \dots, \gamma\left(\Psi_{2n}\right)\}$ is not a Helson set.
\end{lemma}
\begin{proof}
  Also has do to with the mesh condition.
\end{proof}

\begin{proposition}
  \label{prop:Helson}
  \uses{def:Helson_set}
  If $\gamma$ is an increasing homeomorphism of $\mathbb{I}$ that does not coincide with a polynomial of degree less than $n$ on any subinterval of $\mathbb{I}$, then $\gamma\left(E\right)$ is quasi-surely a Helson set. Moreover, the condition on $\gamma$ is necessary and sufficient, and $\chi_q \in A^+\left(\mathbb{I}\right)$ where $A^+\left(\mathbb{I}\right)$ is a class of functions $\chi\left(z\right) = \sum\limits_{j = 0}^\infty \widehat{a}_j e^{2\pi \imath j z}$.
\end{proposition}
\begin{proof}
   ``The proof relies on the following proposition, which is very similar to one given in [Kahane's 1975 article] p. 233 and can be proven in the same way.'' 
   \begin{quote}
    Let $B\left(\mathbb{I}\right)$ be a Banach space contained in $C\left(\mathbb{I}\right)$ and satisfying hypothesis (H): there exists $c > 0$ such that, for any $\delta > 0$, there exist finite sets $D_p\subset I$ (for $p = 1, 2, \ldots, n$) with at least one point in every subinterval of length $\delta$, such that the mapping $D_1\times D_2\times \dots \times D_n \to D_1 + D_2 + \ldots + D_n$ is injective, and for any function $u$ of modulus 1 on the set $D_1 + D_2 + \ldots + D_n$, there exists $\chi\in B\left(\mathbb{I}\right)$, with $\left|\left|\chi\right|\right|_{B\left(\mathbb{I}\right)} \leq c$ and $\left|\left|\chi\right|\right|_{C\left(\mathbb{I}\right)} = 1$, where $\chi = u$ on $D_1 + D_2 + \ldots + D_n$. Then one can choose $\chi \in B\left(\mathbb{I}\right)$.
    \end{quote}
    [I]t follows [from Kronecker's theorem] that any function of modulus 1 on $\mathbb{I}$ can be written as $\sum\limits_{j = 1}^\infty a_j e^{\imath j z}$, with $\sum\limits_{j = 1}^\infty \left|a_j\right| \leq 2$. By applying the proposition, we can therefore take $\chi \in (A \circ \gamma)\left(\mathbb{I}\right)$ as soon as homeomorphism $\gamma$ satisfies the condition:
    \begin{quote}
    For every $\delta > 0$, there exist finite sets $D_p \subset \mathbb{I}$ (for $p = 1, 2, \ldots, n$) at least one point in every subinterval of $\mathbb{I}$ of length $\delta$, such that the mapping $D_1 \times D_2\times \ldots D_n \to D_1 + D_2 + \ldots + D_n$ is injective, and $\gamma(D_1 + D_2 + \ldots + D_n)$ is a rationally independent set.
   \end{quote}
\end{proof}

Then $\chi_q\left(\gamma\left(\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right)\right)\right) = \sum\limits_{j = 0}^\infty \widehat{a}_j e^{2\pi \imath j \left(\gamma\left(\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right)\right) + q\right)} = \sum\limits_{j = 0}^\infty \widehat{a}_j e^{2\pi \imath j \left(\gamma\left(\Psi_q\left(x_0, x_1, \cdots, x_{n - 1}\right)\right)\right)}$ because it is periodic. In practice, we would have to estimate a (truncated) sequence of coefficients to calibrate to a particular target function.

\chapter{Open Problems}\label{ch:OpenProblems}

There are several that I have not written up yet.

\bibliographystyle{plain} % Choose your preferred citation style
\bibliography{references}  % Name of your BibTeX file
\nocite{*}  % Include all entries in the bibliography

